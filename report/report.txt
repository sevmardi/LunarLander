
## Abstract
-----------
In this paper our aim is to solve the self-taught lunar lander task with reinforcement learning agent with no prior knowledge of control. The goal for the agent is to learn the dynamics of the lunar lander and perform a soft landing on a designated landing zone. The agent's learning process is completelty automated and unsupervised, merely based on observable reward from its surroudings (environment). We deomposed the task into two parts: the stable controle task and the direct landing task and created simulated environments for each task. We then worked and imporvised with Policy Gradient algorithm to train our agents. Our experiments showed it is possible to solve the self-taught lunar lander task with this approach. Furthermore, we want to invesitage more general approaches to solve self-taught control policies in the future. 


## Introduction
--------------
The orginal lunar lander task requires an agent to perform soft landigs on designated landing zones with controlable thrust and rotation. It was first introduced in 1979 in a game developed by Atari, Inc. and became a wide spread game concept. Recently the same idea and concept was used on real world rockets such as Falcon 9 rocket by SpaceX, which we somehow drew inspiration and elicited us to invistage further. Instead of using traditioal approache, we wanted to study whether there were methods other than explicitly programmed control algorithms. 

One of methods and core idea of this paper is using reinforcement learning, which is in its trun capable of learning through unknown dynamics of an environment. In the reinfrocement learning per


## Related Work
---------------



## Problem Description
-----------------------


## Background
-------------


## Approach
------------


## Experiments
--------------


## Conclusions
---------------


## Future work
--------------



## Ref
------

[1] Zhangbo Liu.: A Guided Genetic Algorithm for the Planning in Lunar Lander Games
[2] Barry David Nichols.: Reinforcement learning in continuous state-and action-space
[3] H. Hans.: Reinforcement Learning in Continuous State Spaces 
[4] R. Shariff, T. Dick.: Lunar Lander: A Continuous-Action Case Study for Policy-Gradient Actor-Critic Algorithms